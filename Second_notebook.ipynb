{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-30T05:32:34.657942Z","iopub.execute_input":"2022-08-30T05:32:34.659011Z","iopub.status.idle":"2022-08-30T05:32:34.691819Z","shell.execute_reply.started":"2022-08-30T05:32:34.658887Z","shell.execute_reply":"2022-08-30T05:32:34.690713Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Problem Anaylsis\nWe want to comapre 2 documents (a resume and job description) and rank the resumes according to therir revlance, this needs a computional defintion of relevance.\n\n### Ranking Function depends on\n1- BOW representation for words (according to many courses I studied and searching through the internet), and my guess for that, is that we don't need contextual representation for words, we only need one vector for each word to be able to measure similarity between 2 documents.\n\n2- TF-IDF,and this is for the same reason above, we don't need SBERT to represent every word, we're only looking for occurrence of keywords, we're not looking through a story.\n\n3-Document Length\n### Text Retreival Methods\n1- simalirity based models (for example: vector space model or VSM)\n\n2- probalistic models \nand others..\n\n\nAt our case we could use first method, in which we rank the resume based on how much it's similar to the job describtion\n\n\n","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('popular')\nfrom nltk.corpus import stopwords\n\n\nimport string","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:35:51.512462Z","iopub.execute_input":"2022-08-30T05:35:51.512993Z","iopub.status.idle":"2022-08-30T05:35:54.341831Z","shell.execute_reply.started":"2022-08-30T05:35:51.512948Z","shell.execute_reply":"2022-08-30T05:35:54.339688Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:35:54.344245Z","iopub.execute_input":"2022-08-30T05:35:54.346393Z","iopub.status.idle":"2022-08-30T05:35:54.352405Z","shell.execute_reply.started":"2022-08-30T05:35:54.346341Z","shell.execute_reply":"2022-08-30T05:35:54.351231Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"resumes = pd.read_csv('/kaggle/input/summlink-resumes-matching-score/resumes.csv')\n#resumes.iloc[:, 1].values\n#resumes.loc[:, 'resume_text']\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:23:11.169437Z","iopub.execute_input":"2022-08-30T07:23:11.169880Z","iopub.status.idle":"2022-08-30T07:23:11.188025Z","shell.execute_reply.started":"2022-08-30T07:23:11.169848Z","shell.execute_reply":"2022-08-30T07:23:11.186768Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"#### creating dictionary of keys as person name, values as his/her resume","metadata":{}},{"cell_type":"code","source":"resumes_dict = {}\nfor i in range(len(resumes)):\n    resumes_dict[resumes.iloc[i, 0]] = resumes.iloc[i, 1]\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:36:00.144305Z","iopub.execute_input":"2022-08-30T05:36:00.145185Z","iopub.status.idle":"2022-08-30T05:36:00.156959Z","shell.execute_reply.started":"2022-08-30T05:36:00.145141Z","shell.execute_reply":"2022-08-30T05:36:00.155959Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def tokenized_list(resume_doc):\n    resume_doc = str(resume_doc)\n    resume_doc = resume_doc.replace('[' , ' ')\n    resume_doc = resume_doc.replace(']' , ' ')\n    tokens = nltk.word_tokenize(resume_doc.lower().strip())\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:36:02.820028Z","iopub.execute_input":"2022-08-30T05:36:02.820463Z","iopub.status.idle":"2022-08-30T05:36:02.826506Z","shell.execute_reply.started":"2022-08-30T05:36:02.820428Z","shell.execute_reply":"2022-08-30T05:36:02.825162Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def stemmer(tokens):\n    ps = nltk.stem.PorterStemmer()\n    stemmed = []\n    for word in tokens:\n        stemmed.append(ps.stem(word))\n    return stemmed    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T05:36:04.032556Z","iopub.execute_input":"2022-08-30T05:36:04.033357Z","iopub.status.idle":"2022-08-30T05:36:04.040299Z","shell.execute_reply.started":"2022-08-30T05:36:04.033305Z","shell.execute_reply":"2022-08-30T05:36:04.038754Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ndef remove_stops(doc):\n    clean = []\n    #doc = re.sub(r'(.)\\1+', r' ', doc) #removing aaaaaaaaaa for similarity measuers\n    print(doc)\n    for word in doc:\n        if word not in stop_words:\n            clean.append(word)\n    return clean        \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:38:42.950183Z","iopub.execute_input":"2022-08-30T07:38:42.950666Z","iopub.status.idle":"2022-08-30T07:38:42.958221Z","shell.execute_reply.started":"2022-08-30T07:38:42.950629Z","shell.execute_reply":"2022-08-30T07:38:42.957272Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":"### removing 'AAAAAA' words for computation resources  ","metadata":{}},{"cell_type":"code","source":"def a_letters(a_word):\n    i =0\n    for l in a_word:\n        if l == 'A':\n            i+=1\n        if i>= 3:\n            a_word = \" \"\n    return a_word\n","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:38:43.150442Z","iopub.execute_input":"2022-08-30T07:38:43.151034Z","iopub.status.idle":"2022-08-30T07:38:43.155891Z","shell.execute_reply.started":"2022-08-30T07:38:43.150994Z","shell.execute_reply":"2022-08-30T07:38:43.155087Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"#clean_corpus  ","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:38:43.653217Z","iopub.execute_input":"2022-08-30T07:38:43.654471Z","iopub.status.idle":"2022-08-30T07:38:43.659828Z","shell.execute_reply.started":"2022-08-30T07:38:43.654426Z","shell.execute_reply":"2022-08-30T07:38:43.658115Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"clean_corpus = []\nfor doc in resumes_dict.values():\n    #match = re.search(r'(A)\\1+', doc)\n    #new_match = a_letters(match.group())\n    #print(new_match)\n    doc = re.sub(r'(A)\\1+',lambda x: a_letters(x.group()), doc)\n    tokens = tokenized_list(doc)\n    doc = remove_stops(tokens)\n    doc = stemmer(doc)\n    doc = ' '.join(doc)\n    clean_corpus.append(doc)\n#clean_corpus    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:38:50.017968Z","iopub.execute_input":"2022-08-30T07:38:50.018633Z","iopub.status.idle":"2022-08-30T07:38:50.023743Z","shell.execute_reply.started":"2022-08-30T07:38:50.018597Z","shell.execute_reply":"2022-08-30T07:38:50.022380Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"vecotrizer = TfidfVectorizer(sublinear_tf = True)\nvecotrizer.fit(clean_corpus)\ncorpus_space_vector = vecotrizer.transform(clean_corpus)\n\n#print(vecotrizer.get_feature_names())\nprint(corpus_space_vector.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:44:21.216666Z","iopub.execute_input":"2022-08-30T07:44:21.217381Z","iopub.status.idle":"2022-08-30T07:44:21.266408Z","shell.execute_reply.started":"2022-08-30T07:44:21.217341Z","shell.execute_reply":"2022-08-30T07:44:21.264856Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(corpus_space_vector.toarray(), columns = vecotrizer.get_feature_names())\ndf.iloc[:, 2000:2100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2022-08-30T07:59:39.970316Z","iopub.execute_input":"2022-08-30T07:59:39.970747Z","iopub.status.idle":"2022-08-30T07:59:39.976399Z","shell.execute_reply.started":"2022-08-30T07:59:39.970713Z","shell.execute_reply":"2022-08-30T07:59:39.975092Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"job_description = pd.read_json('../input/summlink-resumes-matching-score/job_description_response.json')\njob_description.loc[:, 'description'].values","metadata":{"execution":{"iopub.status.busy":"2022-08-30T08:08:09.571240Z","iopub.execute_input":"2022-08-30T08:08:09.571674Z","iopub.status.idle":"2022-08-30T08:08:09.587789Z","shell.execute_reply.started":"2022-08-30T08:08:09.571637Z","shell.execute_reply":"2022-08-30T08:08:09.586643Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"markdown","source":"### evaluating the necessary skills, we do this so can filter top 10 for example when evaluating addtional skills\n### but for submission file we will compute for all 32 anyway","metadata":{}},{"cell_type":"code","source":"must_have_skills_query = \" experience as a business analyst in a similar environment.\\\n                            experience with business process development and optimization BPM\\\n                            experience with stakeholder management\\\n                            experience within the Belgian energy sector\\\n                            experience with writing processes and instructions\\\n                            experience with SAP\\\n                           \"\nclean_must_query = []\ntokens = tokenized_list(must_have_skills_query)\nmust_have_skills_query = remove_stops(tokens)\nmust_have_skills_query = stemmer(must_have_skills_query)\nmust_have_skills_query = ' '.join(must_have_skills_query)\nclean_must_query.append(must_have_skills_query)\nmust_query_space_vector = vecotrizer.transform(clean_must_query)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:15:33.453569Z","iopub.execute_input":"2022-08-30T09:15:33.455161Z","iopub.status.idle":"2022-08-30T09:15:33.466228Z","shell.execute_reply.started":"2022-08-30T09:15:33.455102Z","shell.execute_reply":"2022-08-30T09:15:33.464771Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nmust_cosine_simi = cosine_similarity(corpus_space_vector, must_query_space_vector).flatten()\nmust_skills_rank = must_cosine_simi.argsort()[:-32:-1]\nmust_skills_rank","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:19:51.245650Z","iopub.execute_input":"2022-08-30T09:19:51.246197Z","iopub.status.idle":"2022-08-30T09:19:51.259187Z","shell.execute_reply.started":"2022-08-30T09:19:51.246154Z","shell.execute_reply":"2022-08-30T09:19:51.257428Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"markdown","source":"### evaluating the addtional skills for top candidates who had the necessary skills","metadata":{}},{"cell_type":"code","source":"add_have_skills_query = \"experience in training end users.\\\n                      experience working on large, complex projects\\\n                      \"\n\nclean_add_query = []\ntokens = tokenized_list(add_have_skills_query)\nadd_have_skills_query = remove_stops(tokens)\nadd_have_skills_query = stemmer(add_have_skills_query)\nadd_have_skills_query = ' '.join(add_have_skills_query)\nclean_add_query.append(add_have_skills_query)\nadd_query_space_vector = vecotrizer.transform(clean_add_query)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:20:14.226685Z","iopub.execute_input":"2022-08-30T09:20:14.227170Z","iopub.status.idle":"2022-08-30T09:20:14.239679Z","shell.execute_reply.started":"2022-08-30T09:20:14.227132Z","shell.execute_reply":"2022-08-30T09:20:14.237854Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"add_cosine_simi = cosine_similarity(corpus_space_vector, add_query_space_vector).flatten()\nadd_skills_rank = add_cosine_simi.argsort()[:-32:-1]\nadd_skills_rank","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:20:35.702639Z","iopub.execute_input":"2022-08-30T09:20:35.703098Z","iopub.status.idle":"2022-08-30T09:20:35.712804Z","shell.execute_reply.started":"2022-08-30T09:20:35.703056Z","shell.execute_reply":"2022-08-30T09:20:35.711834Z"},"trusted":true},"execution_count":298,"outputs":[]},{"cell_type":"markdown","source":"### adding 2 scores to determine overall top 32 resumes","metadata":{}},{"cell_type":"code","source":"total_simi = must_cosine_simi + add_cosine_simi\nonerall_rank = total_simi.argsort()[:-32:-1]\nonerall_rank","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:22:42.031475Z","iopub.execute_input":"2022-08-30T09:22:42.031889Z","iopub.status.idle":"2022-08-30T09:22:42.039897Z","shell.execute_reply.started":"2022-08-30T09:22:42.031857Z","shell.execute_reply":"2022-08-30T09:22:42.038648Z"},"trusted":true},"execution_count":301,"outputs":[]},{"cell_type":"code","source":"simi_list = total_simi.tolist().sort()","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:24:38.888639Z","iopub.execute_input":"2022-08-30T09:24:38.889526Z","iopub.status.idle":"2022-08-30T09:24:38.894854Z","shell.execute_reply.started":"2022-08-30T09:24:38.889482Z","shell.execute_reply":"2022-08-30T09:24:38.893809Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"markdown","source":"### adding score colmun to original dataframe ","metadata":{}},{"cell_type":"code","source":"resumes_with_score = resumes.copy()\nresumes_with_score['rank'] = total_simi\n\nresumes_with_score = resumes_with_score.sort_values('rank',ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:35:29.195363Z","iopub.execute_input":"2022-08-30T09:35:29.195779Z","iopub.status.idle":"2022-08-30T09:35:29.205275Z","shell.execute_reply.started":"2022-08-30T09:35:29.195745Z","shell.execute_reply":"2022-08-30T09:35:29.203599Z"},"trusted":true},"execution_count":321,"outputs":[]},{"cell_type":"code","source":"resumes_with_score = resumes_with_score.drop(resumes_with_score.columns[1], axis=1)\nresumes_with_score","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:44:48.107869Z","iopub.execute_input":"2022-08-30T09:44:48.108352Z","iopub.status.idle":"2022-08-30T09:44:48.128387Z","shell.execute_reply.started":"2022-08-30T09:44:48.108319Z","shell.execute_reply":"2022-08-30T09:44:48.127143Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"code","source":"resumes_with_score.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-30T09:46:09.593394Z","iopub.execute_input":"2022-08-30T09:46:09.593861Z","iopub.status.idle":"2022-08-30T09:46:09.602739Z","shell.execute_reply.started":"2022-08-30T09:46:09.593828Z","shell.execute_reply":"2022-08-30T09:46:09.601001Z"},"trusted":true},"execution_count":340,"outputs":[]}]}